# import requests
# from bs4 import BeautifulSoup
# import csv
# import openpyxl

# # Read the URLs and titles from the CSV file generated by the previous code
# products = []
# with open("amazon_laptops.csv", "r", newline="", encoding="utf-8") as csv_file:
#     csv_reader = csv.reader(csv_file)
#     next(csv_reader)  # Skip header
#     for row in csv_reader:
#         if row[1] != "Information not available":  # Check if the URL is valid
#             products.append({"Title": row[0], "URL": row[1]})

# # Create a new CSV file to write the extracted product details
# csv_filename = "product_details.csv"
# with open(csv_filename, "w", newline="", encoding="utf-8") as csv_file:
#     csv_writer = csv.writer(csv_file)
#     csv_headers = ["Title", "ASIN", "Manufacturer", "Description"]
#     csv_writer.writerow(csv_headers)

#     # Create an Excel workbook and sheet
#     wb = openpyxl.Workbook()
#     sheet = wb.active
#     excel_headers = ["Title", "ASIN", "Manufacturer", "Description"]
#     sheet.append(excel_headers)

#     # Iterate through the products and scrape additional information
#     for product in products:
#         url = product["URL"]
#         response = requests.get(url)
#         soup = BeautifulSoup(response.content, "html.parser")

#         # Extract ASIN
#         asin = ""
#         asin_th = soup.find("th", text="Best Sellers Rank")
#         if asin_th:
#             asin_td = asin_th.find_next_sibling("td", class_="a-size-base prodDetAttrValue")
#             asin = asin_td.get_text(strip=True)

#         # Extract Manufacturer
#         manufacturer = ""
#         manufacturer_th = soup.find("th", text="Packer")
#         if manufacturer_th:
#             manufacturer_td = manufacturer_th.find_next_sibling("td", class_="a-size-base prodDetAttrValue")
#             manufacturer = manufacturer_td.get_text(strip=True)

#         # Extract Description
#         description_list = []
#         description_elements = soup.select("#feature-bullets ul.a-unordered-list.a-vertical.a-spacing-mini > li.a-spacing-mini > span.a-list-item")
#         for element in description_elements:
#             description_list.append(element.get_text(strip=True))
#         description = "\n".join(description_list) if description_list else "Information not available"

#         # Write the extracted data to the CSV file
#         csv_writer.writerow([product["Title"], asin, manufacturer, description])

#         # Write the extracted data to the Excel sheet
#         sheet.append([product["Title"], asin, manufacturer, description])

#     # Save the Excel file
#     wb.save("product_details.xlsx")

# print("Product details have been extracted and saved to both product_details.csv and product_details.xlsx")


# import requests
# from bs4 import BeautifulSoup
# import csv
# import openpyxl

# # Read the URLs and titles from the CSV file generated by the previous code
# products = []
# with open("amazon_laptops.csv", "r", newline="", encoding="utf-8") as csv_file:
#     csv_reader = csv.reader(csv_file)
#     next(csv_reader)  # Skip header
#     for row in csv_reader:
#         if row[1] != "Information not available":  # Check if the URL is valid
#             products.append({"Title": row[0], "URL": row[1]})

# # Create a new CSV file to write the extracted product details
# csv_filename = "product_details.csv"
# with open(csv_filename, "w", newline="", encoding="utf-8") as csv_file:
#     csv_writer = csv.writer(csv_file)
#     csv_headers = ["Title", "Brand", "Model Name", "Screen Size", "Colour", "Hard Disk Size", "CPU Model", "RAM Memory Installed Size", "Operating System"]
#     csv_writer.writerow(csv_headers)

#     # Create an Excel workbook and sheet
#     wb = openpyxl.Workbook()
#     sheet = wb.active
#     excel_headers = ["Title", "Brand", "Model Name", "Screen Size", "Colour", "Hard Disk Size", "CPU Model", "RAM Memory Installed Size", "Operating System"]
#     sheet.append(excel_headers)

#     # Iterate through the products and scrape additional information
#     for product in products:
#         url = product["URL"]
#         response = requests.get(url)
#         soup = BeautifulSoup(response.content, "html.parser")

#         # Extract product details
#         details_table = soup.find("table", class_="a-normal a-spacing-micro")
#         if details_table:
#             details = {}
#             for row in details_table.find_all("tr"):
#                 cells = row.find_all("td")
#                 if len(cells) == 2:
#                     label = cells[0].text.strip()
#                     value = cells[1].text.strip()
#                     details[label] = value

#             # Write the extracted data to the CSV file
#             csv_writer.writerow([
#                 product["Title"],
#                 details.get("Brand", "Information not available"),
#                 details.get("Model Name", "Information not available"),
#                 details.get("Screen Size", "Information not available"),
#                 details.get("Colour", "Information not available"),
#                 details.get("Hard Disk Size", "Information not available"),
#                 details.get("CPU Model", "Information not available"),
#                 details.get("RAM Memory Installed Size", "Information not available"),
#                 details.get("Operating System", "Information not available")
#             ])

#             # Write the extracted data to the Excel sheet
#             sheet.append([
#                 product["Title"],
#                 details.get("Brand", "Information not available"),
#                 details.get("Model Name", "Information not available"),
#                 details.get("Screen Size", "Information not available"),
#                 details.get("Colour", "Information not available"),
#                 details.get("Hard Disk Size", "Information not available"),
#                 details.get("CPU Model", "Information not available"),
#                 details.get("RAM Memory Installed Size", "Information not available"),
#                 details.get("Operating System", "Information not available")
#             ])

    # Save the Excel file
#     wb.save("product_details.xlsx")

# print("Product details have been extracted and saved to both product_details.csv and product_details.xlsx")















# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# # Read URLs from CSV file
# url_df = pd.read_csv("amazon_laptops.csv")
# urls = url_df["URL"].tolist()

# # Initialize lists to store product details
# titles = []
# brands = []
# model_names = []
# screen_sizes = []
# colours = []
# hard_disk_sizes = []
# cpu_models = []
# ram_memories = []
# operating_systems = []

# for url in urls:
#     if url != "Information not available":
#         response = requests.get(url)
#         soup = BeautifulSoup(response.content, "html.parser")

#         title = url_df.loc[url_df["URL"] == url, "Title"].iloc[0]  # Extract title using the corresponding URL
#         titles.append(title)

#         details_table = soup.find("table", class_="a-normal a-spacing-micro")
#         if details_table:
#             product_info = {}
#             for row in details_table.find_all("tr"):
#                 columns = row.find_all("td")
#                 if len(columns) == 2:
#                     key = columns[0].find("span", class_="a-size-base").text.strip()
#                     value = columns[1].find("span", class_="a-size-base").text.strip()
#                     product_info[key] = value

#             brands.append(product_info.get("Brand", "Information not available"))
#             model_names.append(product_info.get("Model Name", "Information not available"))
#             screen_sizes.append(product_info.get("Screen Size", "Information not available"))
#             colours.append(product_info.get("Colour", "Information not available"))
#             hard_disk_sizes.append(product_info.get("Hard Disk Size", "Information not available"))
#             cpu_models.append(product_info.get("CPU Model", "Information not available"))
#             ram_memories.append(product_info.get("RAM Memory Installed Size", "Information not available"))
#             operating_systems.append(product_info.get("Operating System", "Information not available"))
#         else:
#             brands.append("Information not available")
#             model_names.append("Information not available")
#             screen_sizes.append("Information not available")
#             colours.append("Information not available")
#             hard_disk_sizes.append("Information not available")
#             cpu_models.append("Information not available")
#             ram_memories.append("Information not available")
#             operating_systems.append("Information not available")

# # Create a DataFrame from the extracted data
# data = {
#     "Title": titles,
#     "Brand": brands,
#     "Model Name": model_names,
#     "Screen Size": screen_sizes,
#     "Colour": colours,
#     "Hard Disk Size": hard_disk_sizes,
#     "CPU Model": cpu_models,
#     "RAM Memory Installed Size": ram_memories,
#     "Operating System": operating_systems,
# }
# df = pd.DataFrame(data)

# # Save DataFrame to Excel and CSV files
# df.to_excel("amazon_product.xlsx", index=False)
# df.to_csv("amazon_product.csv", index=False)








import requests
from bs4 import BeautifulSoup
import csv
import openpyxl

# Read the URLs and titles from the CSV file generated by the previous code
products = []
with open("amazon_laptops.csv", "r", newline="", encoding="utf-8") as csv_file:
    csv_reader = csv.reader(csv_file)
    next(csv_reader)  # Skip header
    for row in csv_reader:
        if row[1] != "Information not available":  # Check if the URL is valid
            products.append({"Title": row[0], "URL": row[1]})

# Create a new CSV file to write the extracted product details
csv_filename = "product_details.csv"
with open(csv_filename, "w", newline="", encoding="utf-8") as csv_file:
    csv_writer = csv.writer(csv_file)
    csv_headers = ["Title", "Brand", "Model Name", "Screen Size", "Colour", "Hard Disk Size", "CPU Model", "RAM Memory Installed Size", "Operating System"]
    csv_writer.writerow(csv_headers)

    # Create an Excel workbook and sheet
    wb = openpyxl.Workbook()
    sheet = wb.active
    excel_headers = ["Title", "Brand", "Model Name", "Screen Size", "Colour", "Hard Disk Size", "CPU Model", "RAM Memory Installed Size", "Operating System"]
    sheet.append(excel_headers)

    # Iterate through the products and scrape additional information
    for product in products:
        title = product["Title"]
        url = product["URL"]
        HEADERS = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}
        response = requests.get(url,headers=HEADERS)
        soup = BeautifulSoup(response.content, "html.parser")

        # Extract product details
        details_table = soup.find("table", class_="a-normal a-spacing-micro")
        if details_table:
            details = {}
            rows = details_table.find_all("tr")
            for row in rows:
                cells = row.find_all("td")
                if len(cells) == 2:
                    label = cells[0].get_text(strip=True)
                    value = cells[1].get_text(strip=True)
                    details[label] = value

            # Write the extracted data to the CSV file
            csv_writer.writerow([
                title,
                details.get("Brand", "Information not available"),
                details.get("Model Name", "Information not available"),
                details.get("Screen Size", "Information not available"),
                details.get("Colour", "Information not available"),
                details.get("Hard Disk Size", "Information not available"),
                details.get("CPU Model", "Information not available"),
                details.get("RAM Memory Installed Size", "Information not available"),
                details.get("Operating System", "Information not available")
            ])

            # Write the extracted data to the Excel sheet
            sheet.append([
                title,
                details.get("Brand", "Information not available"),
                details.get("Model Name", "Information not available"),
                details.get("Screen Size", "Information not available"),
                details.get("Colour", "Information not available"),
                details.get("Hard Disk Size", "Information not available"),
                details.get("CPU Model", "Information not available"),
                details.get("RAM Memory Installed Size", "Information not available"),
                details.get("Operating System", "Information not available")
            ])

    # Save the Excel file
    wb.save("product_details.xlsx")

print("Product details have been extracted and saved to both product_details.csv and product_details.xlsx")
